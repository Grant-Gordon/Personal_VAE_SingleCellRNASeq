//mental_model.txt

python front end:
    ***     
        contains get_npz_chunk_csr_array_pointers() util function that cpp calls,
        contains config.yaml/json and cpp_config_generator() util
        contains training stats processor that generates figures from training log files.
    ***
    -takes in config yaml
    -parses config and generates config.hpp
    -python calls cmake with import subprocess
    -python calls train_model() passing off to the cpp backend
    -python does some logging/output processing/figure gen

cpp backend
    *** 
        contains full model architecture,
        contains full trianing loop,
        contains batch creation that calls python util to get pointers to chunked data
        contains basic logging functions that write to file format that is easy for cpp to write to and python to read from. 
    ***
    -initializes model, weights, optimizer, etc.
    -for epoch
        -shuffle chunks_list
        -for chunk in chunks_list
            -pull npz chunk pointers using python util method
            -BatchCreator(chunk, num_preloader, num_workers)
                |___batch crator, immediatly begins preloading batches, 
            -while (BatchCreator not done)
                |__trainer.train_on_batch(BatchCreator::batchQ.top())
              
                -write batch level stats
            
            -write chunk level stats

        -write epoch level stats
    
    -write training summary stats
    -save model
    -pass back to python for training stats processing


//mental_model.txt
    ***
    Training loop specs
    ***

        for chunk 
            BatchCreator bc = BatchCreator(chunk)
                |___ shuffles splits chunk_ids;
                    -
            bc.prelaod_batches()
                |___ for batch_ids in shuffled_split_chunk_ids
                        bc.generate_batch(batch_ids)
                            |___for sample_id in batch_ids{}
                                    generate SSR sample from csr pointers
                                    add SSR* to batch Vector

                
            while( ! bc.all_batches_preloaded){
                train_on_batch(bc::batchQ.top())
            }

            train on batch:
                model forward(batch)
                    |___computes MSE loss with vector<SSR> targets X dense reconstruction (some compute time to itterate SSR ptrs)
                free vector<SSR> (for each batch, R/W sizeof(SSR) * batch size)
               